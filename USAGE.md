# ğŸš€ SystÃ¨me de DÃ©tection d'Anomalies en Temps RÃ©el

## Architecture Ultra-SimplifiÃ©e âœ¨

- **100% Spark SQL natif** - Pas de numpy/sklearn/joblib
- **Z-Score pur** - DÃ©tection d'anomalies par Ã©cart statistique  
- **Kafka + Spark Streaming** - Pipeline temps rÃ©el scalable
- **Docker tout-en-un** - Infrastructure complÃ¨te en local

## DÃ©marrage Rapide âš¡

### 1. Lancer tout le systÃ¨me

```bash
# Rendre le script exÃ©cutable (premiÃ¨re fois)
chmod +x run_all.sh

# Lancer l'infrastructure complÃ¨te
./run_all.sh
```

Ce script va :
- âœ… DÃ©marrer Kafka + Spark
- âœ… CrÃ©er le topic `transactions`  
- âœ… Tester la connectivitÃ©
- âœ… Lancer la dÃ©tection d'anomalies

### 2. GÃ©nÃ©rer des donnÃ©es de test

Dans un **autre terminal** :

```bash
python3 generate_test_data.py
```

Cela va envoyer :
- ğŸ“Š Transactions normales : 20-200â‚¬
- ğŸš¨ Anomalies artificielles : >500â‚¬ ou <5â‚¬ (10% de chance)

## Comment Ã§a fonctionne ğŸ”¬

### DÃ©tection Z-Score

```sql
z_score = |amount - moyenne_fenÃªtre| / ecart_type_fenÃªtre
anomalie = z_score > 3.0
```

### FenÃªtres temporelles

- **FenÃªtre** : 1 minute  
- **Slide** : 30 secondes
- **Watermark** : 5 minutes (tolÃ©rance late data)

### Sortie

Le systÃ¨me affiche en temps rÃ©el :
- Toutes les transactions avec leur z-score
- Filtrage spÃ©cial des anomalies dÃ©tectÃ©es

## Surveillance ğŸ“Š

### Logs Spark
```bash
docker-compose logs -f spark-master
```

### Interfaces Web
- **Spark Master** : http://localhost:8080  
- **Spark Worker** : http://localhost:8081

### Topics Kafka
```bash
# Lister les topics
docker-compose exec kafka kafka-topics --bootstrap-server kafka:9092 --list

# Consommer les messages
docker-compose exec kafka kafka-console-consumer \
  --bootstrap-server kafka:9092 \
  --topic transactions \
  --from-beginning
```

## ArrÃªt du systÃ¨me â¹ï¸

```bash
# ArrÃªter proprement
docker-compose down

# Nettoyage complet (volumes inclus)
docker-compose down --volumes
```

## Avantages de cette approche âœ…

1. **ZÃ©ro dÃ©pendance Python complexe** - Plus de problÃ¨mes numpy/_core
2. **Ultra-rapide** - Calculs natifs Spark, pas de sÃ©rialisation Python  
3. **Scalable** - Peut traiter des millions de transactions
4. **Production-ready** - Watermarks, checkpoints, gestion d'erreurs
5. **Simple** - Une seule commande pour tout dÃ©marrer

## Personnalisation ğŸ›ï¸

### Changer le seuil d'anomalie
Dans `src/spark_stream.py` :
```python
ANOMALY_THRESHOLD = 3.0  # Modifier cette valeur
```

### Ajuster les fenÃªtres
```python
window(col("timestamp"), "1 minute", "30 seconds")  # durÃ©e, slide
```

### Modifier le watermark  
```python
.withWatermark("timestamp", "5 minutes")  # tolÃ©rance late data
```

ğŸ‰ **SystÃ¨me prÃªt pour la production !**